{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- Cross validation\n",
    "- Confusion Matrix\n",
    "- Sensitivity vs specificity \n",
    "- Bias and Variance\n",
    "\n",
    "\n",
    "## Cross validation\n",
    "\n",
    "Lets say we have variables **height, age , weight** to predict **health**\n",
    "We can use logistic regression or k nearest neighbor or support vector machines or any ML Method\n",
    "\n",
    "**Cross validation** allows us to compare different machine learning methods and get a sense of how well they will work in practice\n",
    "\n",
    "With the data we have we need to do 2 things:\n",
    "\n",
    "1) Estimate the parameters for the machine learning methods or \"train the algorithm\"\n",
    "\n",
    "**NEVER USE ALL THE DATA TO TRAIN THE ALGORITHM** bc you wont have any data to test the algorithm\n",
    "\n",
    "\n",
    "2) Evaluate how well teh machine learning methods work. or \"testing the algorithm\"\n",
    "\n",
    "Imagine we split the data into 4 blocks 75% of the data for training and the last 25% for testing\n",
    "\n",
    "### But how do we know that the first 75% of the data we used is the best way to divide the data?\n",
    "\n",
    "**Crossvalidation** uses all possiblities of dividing the data one at a time and then summarizes the results at the end\n",
    "\n",
    "\n",
    "At the end we can see how every block of data is used for testing and can **compare** ML methods to see how well they preformed\n",
    "![MLF1](images/MLF1.PNG)\n",
    "\n",
    "Terminology:\n",
    "In the example above we divided the data into 4 blocks this is called **Four fold Cross validation**\n",
    "  the number of blocks is arbitrary\n",
    "  \n",
    "**ten fold cross validation** is dividing the data into 10 blocks  \n",
    "In extreme cases we could seperate each individual into a block this is called **leave one out cross validation**  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "Another way to determine different machine learning methods is by using a confusion matrix\n",
    "\n",
    "it checks performance measurement for machine learning classification\n",
    "![MLF2](images/MLF2.PNG)\n",
    "\n",
    "\n",
    "The rows in a confusino matrix corresponds to what the machine learning algorithm predicted\n",
    "\n",
    "The colums coresponds to the known truth\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLF3](images/MLF3.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the random forest was better than the k nearest neighbors in predicting the patients (142 vs 107)\n",
    "\n",
    "and worse at predicting patients without Heart disease 110 vs 79\n",
    "\n",
    "**So from the picture above we would choose the random forest over the K-nearest Neighbors**\n",
    "\n",
    "###  Ultimately, the size of the confusion matrix is determind by the number of things we want to predict.\n",
    "\n",
    "## Sensitivity vs Specificity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLF4](images/MLF4.PNG)\n",
    "Sensitivity tells us what percentage of patients were correctly identified"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLF5](images/MLF5.PNG)\n",
    "tells us what percentage without heart disease that were correctly identified\n",
    "\n",
    "**Depending on if you want to identify patients with or without heart disease the model you will differ**\n",
    "\n",
    "### Ultimatley we can use sensitivity and specificity to help us decide which machine learning method would be best for our data\n",
    "\n",
    "TLDR:\n",
    "\n",
    "If correctly identifying **positives** is the most important thing to do with the data you should use the method with the higher **Sensitivity**\n",
    "\n",
    "If correctly identifying **negatives** is the most important thing to do with the data you should use the method with the higher **Specificity**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias and varaince\n",
    "imagine a data set of height vs weight\n",
    "![MLF6](images/MLF6.PNG)\n",
    "Lets say we use Linear regression(red line) to try to predict the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLF7](images/MLF7.PNG)\n",
    "**The straight line doesnt have the flexibility to accuratly replicat the arc in the true relationship no matter how well you fit it to the training set**\n",
    "\n",
    "The inability for a machine learning method (in this case linear regression) to capture the true relationship is called **Bias**\n",
    "\n",
    "We can calculate Sum of squares to account for different predictive lines you need to calculate SS on **BOTH** the training data set and the testing data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "In machine learning the differences in fits between datasets(training vs testing) is called variance \n",
    "\n",
    "***Terminology*** \n",
    "If the line fits the **training set** really well but not the **testing set** we say that the line is **overfit**\n",
    "\n",
    "\n",
    "**Ideally we want a model that has low Bias and Variability we need to find the sweet spot between a simple model and a complex model**\n",
    "\n",
    "***Terminology*** \n",
    "\n",
    "Three commonly used emthods for finding the sweet spot between simple and complicated modesl are called\"\n",
    "**Regularization, Boosting, and bagging**\n",
    "\n",
    "*Random forest will show an example of bagging in action refer to that skill*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
