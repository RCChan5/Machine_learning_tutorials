{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "- How linear regression works (simple)\n",
    "- Determining how good the fitted line is using R squared\n",
    "- P values\n",
    "- R\n",
    "- Python\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "Given some data that you think are related, linear regression quantifies the relationship in the data: this is R^2. You want this to be large. It also determines how reliable that relation ship is: this is the p value that we calculate with F. You want this to be small. You need both to have good results\n",
    "\n",
    "\n",
    "## Conditions for linear regression\n",
    "\n",
    "1. Linear relationship: There exists a linear relationship between the independent variable, x, and the dependent variable, y.\n",
    "2. Independence: The residuals are independent. In particular, there is no correlation between consecutive residuals in time series data.\n",
    "3. Homoscedasticity: The residuals have constant variance at every level of x.\n",
    "4. Normality: The residuals of the model are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The steps in a linear regression is:\n",
    "1. Use least squares to fit a line to the data\n",
    "2. Calculate the R^2\n",
    "3. Calculate the p value for R^2\n",
    "\n",
    "## How it works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our Data\n",
    "![LMaR1](images/LMaR1.jpg)\n",
    "First you draw a line through the data and measure the distance from the line to the data and sqaure each distance and then add them up\n",
    "\n",
    "**NOTE**: the distance from the line to the point is called a residual."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR2](images/LMaR2.jpg)\n",
    "Now you rotate the line and measure the residuals, square them, then sum up the squares. to get the sum of squared residuals\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR3](images/LMaR3.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the sum of squared residuals to the coresponding rotation. We want the rotation with the \"least squares\" \n",
    "![LMaR4](images/LMaR4.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a fit line to the data.\n",
    "![LMaR5](images/LMaR5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since the slope is not 0 it means that knowing a mouse weight will help us guess about the mouse's size\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining how good the guess is with R Squared\n",
    "\n",
    "First we calculate the average mouse size\n",
    "![LMaR6](images/LMaR6.jpg)\n",
    "Sum the squared residuals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR7](images/LMaR7.jpg)\n",
    "Like we did in least squares we measure the distance from the mean to the data point and square it this is called: SS(mean)\n",
    "\n",
    "SS(mean) = (data - mean)^2\n",
    "\n",
    "Variation around the mean = SS(mean)/n\n",
    "    \n",
    "    n being the sample size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we go back to our plot and Sum up the residuals around our least squares fit\n",
    "![LMaR8](images/LMaR8.jpg)\n",
    "This is calles SS(fit): for the sum of squares around the least squares fit\n",
    "\n",
    "SS(fit)= (data - line)^2\n",
    "\n",
    "Var(fit)= SS(fit)/n\n",
    "\n",
    "**NOTE**: in general the variance(something) is the \"sum of squares\"/ \"number of those things\"  == Average sum of squares\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR9](images/LMaR9.jpg)\n",
    "We can say that some of the variation in mouse size is \"explained\" by looking at mouse weight\n",
    "\n",
    "Or in simpler terms Heavier mice are Bigger and Lighter mice are Smaller\n",
    "\n",
    "R^2 = (Var(mean) - Var(fit)) / Var(mean)\n",
    "\n",
    "We can thus say that mouse weight explains R^2 % of the variation in mouse size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need a way to determine if the R^2 value is statistically significant**\n",
    "any 2 points can have a line drawn between them and thier r^2 would be 100% \n",
    "\n",
    "Thus we need p values\n",
    "\n",
    "## Pvalues\n",
    "\n",
    "p values for R^2 come from something called F\n",
    "\n",
    "F = Var in size explained by weight / Var in size not explained by weight\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do it in R\n",
    "\n",
    "\n",
    "![LMaR10](images/LMaR10.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot(mouse.data$ weight,mouse.data $size)\n"
     ]
    }
   ],
   "source": [
    "print(\"plot(mouse.data$ weight,mouse.data $size)\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR11](images/LMaR11.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mouse.regression <- lm(size ~ weight, data = mouse.data)\n",
      "summary(mouse.regression)\n"
     ]
    }
   ],
   "source": [
    "print(\"mouse.regression <- lm(size ~ weight, data = mouse.data)\")\n",
    "print(\"summary(mouse.regression)\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LMaR12](images/LMaR12.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the summary\n",
    "The summary function is where all the meat of the linear model can be found.\n",
    "\n",
    "### Residuals\n",
    "\n",
    "is the summary of the residuals(distance from data to the fitted line) you want this to be symmestrically distributed around the line: which means you want the min and max value to be approx. the same distance from 0\n",
    "\n",
    "you also want to 1Q and 3Q the approx the same distance\n",
    "\n",
    "\n",
    "### Coefficents \n",
    "\n",
    "This section tells us about the least squares estimates for the fitted line\n",
    "\n",
    "The std. Error and t value are provided to show how the p values were calculated\n",
    "\n",
    "Pr(>|t|) these are the p values for the estimated parameters. we want the p value for weight to be < .05 that is to be statistically significant\n",
    "\n",
    "A significant p value for weight(seen above) will mean that it will give us a reliable guess of mouse size.\n",
    "\n",
    "### residual standard errror:\n",
    "this is the square root of the denominator in the equiation for F\n",
    "### multiple R squared:\n",
    "this is the R^2 which means weight can be explained by 61% of the size\n",
    "### F statistic:\n",
    "this tells us if your R^2 is significant or not: again you see the p value which says the weight is a reliable estimate for size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to do linear regressions in Python\n",
    "There are 2 libraries that allow for linear regression in python. 1 being **statsmodels** and the other is **sickit-learn** in these notes ill be using scikit learn\n",
    "\n",
    "When using python usually you will also use numpy and pandas for array manipulation and the data structure to hold such array here is an example of what the work flow would look like when using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## librarys you will need to import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # To visualize\n",
    "import pandas as pd  # To read data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "#data = pd.read_csv(\" insert data file here \")  # load data set\n",
    "#X = data.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "#Y = data.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "#linear_regressor = LinearRegression()  # create object for the class\n",
    "#linear_regressor.fit(X, Y)  # perform linear regression\n",
    "#Y_pred = linear_regressor.predict(X)  # make predictions\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(X, Y)\n",
    "#plt.plot(X, Y_pred, color='red')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear regression\n",
    "Lets say we wanted to know if **weight** and **tail** length did a good job at predicting the **length of the mouse's body**\n",
    "![LMaR13](images/LMaR13.jpg)\n",
    "Go to the Multiple Linear regression notes for more info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
